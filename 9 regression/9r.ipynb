{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2tPSiTSPxGM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHT_NBtBP41r"
   },
   "outputs": [],
   "source": [
    "def read(a):\n",
    "    b = pd.read_csv(a, delimiter = ',')\n",
    "    b = b.astype(np.float64)\n",
    "    return b.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MnW8kGzP8Bb"
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        j = 0\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            if j > 1:\n",
    "                break\n",
    "            j+=1\n",
    "\n",
    "\n",
    "\n",
    "def randomCV(clf, X, y, param_grid, n_iter, cv):\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions = param_grid,\n",
    "          n_iter = n_iter, cv = cv, iid = False)\n",
    "    random_search.fit(X, y)\n",
    "    report(random_search.cv_results_)\n",
    "    return random_search.best_params_\n",
    "\n",
    "def Rf(x, y):\n",
    "  clf = RandomForestRegressor()\n",
    "  param_grid = {\n",
    "        \"n_estimators\" : np.arange(2,50),\n",
    "        \"max_depth\" : np.arange(1,6),\n",
    "\n",
    "    # \"criterion\" : ['mse', 'mae'],\n",
    "    # \"min_samples_split\" : np.random.random_sample((100,)),      \n",
    "    # \"min_samples_split\" : np.linspace(0.01,1, num = 1000),\n",
    "    # \"min_samples_leaf\" : np.linspace(0.01,0.5, num = 100),\n",
    "    # \"bootstrap\" : [True, False],\n",
    "    # \"warm_start\" : [True, False]\n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 50, 6)  \n",
    "\n",
    "\n",
    "def Dt(x, y):\n",
    "  clf = DecisionTreeRegressor()\n",
    "  param_grid = {\n",
    "      \"max_depth\" : np.arange(1,6),\n",
    "#       \"min_samples_split\" : np.linspace(0.01,0.5, num = 1000),\n",
    "#       \"min_samples_leaf\" : np.linspace(0.01,0.5, num = 1000),\n",
    "      \"criterion\" : ['mse', 'mae', 'friedman_mse'],\n",
    "      \"splitter\" : ['best', 'random'],\n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 5, 4)  \n",
    "\n",
    "def Svr(x, y):\n",
    "  clf = svm.SVR()\n",
    "  param_grid = {\n",
    "      \"kernel\" : ['poly', 'rbf', 'linear', 'sigmoid'],\n",
    "      \"gamma\" : ['scale', 'auto'],\n",
    "      \"shrinking\" : [True, False]\n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 4, 6)\n",
    "\n",
    "def Ada(x, y):\n",
    "  clf = AdaBoostRegressor()\n",
    "  param_grid = {\n",
    "      \"n_estimators\" : np.arange(1,100),\n",
    "      \"loss\" : ['linear', 'square', 'exponential'],\n",
    "      # \"learning_rate\" : np.arange(1,)\n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 30, 6)\n",
    "\n",
    "def GP(x, y):\n",
    "  clf = GaussianProcessRegressor()\n",
    "  param_grid = {\n",
    "#       \"kernel\" : [RBF, WhiteKernel],\n",
    "      \"normalize_y\" : [True, False],\n",
    "      \"copy_X_train\" : [True, False],\n",
    "      \"alpha\" : np.linspace(0, 3, 100),\n",
    "      \n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 4, 6)\n",
    "\n",
    "def LR(x, y):\n",
    "  clf = LinearRegression()\n",
    "  param_grid = {\n",
    "      \"fit_intercept\" : [True, False],\n",
    "      \"normalize\" : [True, False],\n",
    "      \"copy_X\" : [True, False],\n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 25, 6)\n",
    "\n",
    "def NN(x, y):\n",
    "  clf = MLPRegressor()\n",
    "  param_grid = {\n",
    "      \"hidden_layer_sizes\" : np.arange(1,20),\n",
    "      \"activation\" : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "      \"solver\" : ['lbfgs', 'sgd', 'adam'],\n",
    "      \"learning_rate\" : ['constant', 'invscaling', 'adaptive'],\n",
    "      \"shuffle\" : [True, False],\n",
    "  }\n",
    "  return randomCV(clf, x, y, param_grid, 30, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KsTd-4QP-t0"
   },
   "outputs": [],
   "source": [
    "data = read(\"segm.csv\")\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "y = data[:,-4:]\n",
    "x = data[:,:13]\n",
    "\n",
    "x_test, x_train = np.split(x, [36240])\n",
    "y_test, y_train = np.split(y, [36240])\n",
    "\n",
    "scaler = StandardScaler()                         # scaling features\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_nn = scaler.transform(y_train)\n",
    "y_test_nn = scaler.transform(y_test)\n",
    "\n",
    "\n",
    "# print(y_train.shape, x_train.shape)\n",
    "\n",
    "# np.where(np.isnan(y_train))\n",
    "\n",
    "# y_train = np.nan_to_num(y_train)\n",
    "\n",
    "col_mean = np.nanmean(y_train, axis=0)\n",
    "inds = np.where(np.isnan(y_train))\n",
    "y_train[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "col_mean = np.nanmean(y_test, axis=0)\n",
    "inds = np.where(np.isnan(y_test))\n",
    "y_test[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "col_mean = np.nanmean(x_train, axis=0)\n",
    "inds = np.where(np.isnan(x_train))\n",
    "x_train[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "col_mean = np.nanmean(x_test, axis=0)\n",
    "inds = np.where(np.isnan(x_test))\n",
    "x_test[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "col_mean = np.nanmean(y_train_nn, axis=0)\n",
    "inds = np.where(np.isnan(y_train_nn))\n",
    "y_train_nn[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "col_mean = np.nanmean(y_test_nn, axis=0)\n",
    "inds = np.where(np.isnan(y_test_nn))\n",
    "y_test_nn[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "x_train = x_train[:20000]\n",
    "y_train = y_train[:20000]\n",
    "y_train_nn = y_train_nn[:20000]\n",
    "\n",
    "x_test = x_test[:3000]\n",
    "y_test = y_test[:3000]\n",
    "y_test_nn = y_test_nn[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iEaoelLVQBlK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.600 (std: 0.010)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 4, 'criterion': 'friedman_mse'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.600 (std: 0.010)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 4, 'criterion': 'mse'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.113 (std: 0.004)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 1, 'criterion': 'friedman_mse'}\n",
      "\n",
      "RMSE on test data :  51227.07031289116\n",
      "Score with test data 0.597846380528909\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.634 (std: 0.079)\n",
      "Parameters: {'splitter': 'random', 'max_depth': 5, 'criterion': 'friedman_mse'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.485 (std: 0.084)\n",
      "Parameters: {'splitter': 'random', 'max_depth': 4, 'criterion': 'friedman_mse'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.388 (std: 0.036)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 4, 'criterion': 'mae'}\n",
      "\n",
      "RMSE on test data :  46499.64659619644\n",
      "Score with test data 0.633729906581598\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.771 (std: 0.005)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 5, 'criterion': 'mse'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.610 (std: 0.062)\n",
      "Parameters: {'splitter': 'random', 'max_depth': 5, 'criterion': 'friedman_mse'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.600 (std: 0.010)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 4, 'criterion': 'friedman_mse'}\n",
      "\n",
      "RMSE on test data :  30784.239897333176\n",
      "Score with test data 0.7576276798079904\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.600 (std: 0.009)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 4, 'criterion': 'friedman_mse'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.368 (std: 0.006)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 3, 'criterion': 'mse'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.251 (std: 0.007)\n",
      "Parameters: {'splitter': 'best', 'max_depth': 2, 'criterion': 'mse'}\n",
      "\n",
      "RMSE on test data :  50979.9214213597\n",
      "Score with test data 0.5982017900736394\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------> Run for Decision Tree regressor\n",
    "j = 0\n",
    "for i in y_train.T:\n",
    "    param = Dt(x_train, i)\n",
    "    reg_tree = DecisionTreeRegressor().set_params(**param)\n",
    "    reg_tree.fit(x_train, i)\n",
    "    prediction = reg_tree.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "\n",
    "    print(\"Score with test data\",reg_tree.score(x_test, y_test[:,j]))\n",
    "    print('new data\\n\\n\\n\\n\\n\\n')\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.777 (std: 0.011)\n",
      "Parameters: {'n_estimators': 10, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.777 (std: 0.010)\n",
      "Parameters: {'n_estimators': 35, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.776 (std: 0.011)\n",
      "Parameters: {'n_estimators': 32, 'max_depth': 5}\n",
      "\n",
      "RMSE on test data :  29124.019599508592\n",
      "Score with test data 0.7713644402470934\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.777 (std: 0.009)\n",
      "Parameters: {'n_estimators': 39, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.777 (std: 0.010)\n",
      "Parameters: {'n_estimators': 19, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.776 (std: 0.010)\n",
      "Parameters: {'n_estimators': 47, 'max_depth': 5}\n",
      "\n",
      "RMSE on test data :  30182.30939080593\n",
      "Score with test data 0.76225889680078\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.777 (std: 0.011)\n",
      "Parameters: {'n_estimators': 22, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.777 (std: 0.012)\n",
      "Parameters: {'n_estimators': 8, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.776 (std: 0.011)\n",
      "Parameters: {'n_estimators': 46, 'max_depth': 5}\n",
      "\n",
      "RMSE on test data :  30258.398769026368\n",
      "Score with test data 0.7617677636543077\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.776 (std: 0.012)\n",
      "Parameters: {'n_estimators': 34, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.776 (std: 0.012)\n",
      "Parameters: {'n_estimators': 20, 'max_depth': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.776 (std: 0.010)\n",
      "Parameters: {'n_estimators': 27, 'max_depth': 5}\n",
      "\n",
      "RMSE on test data :  30539.510908828786\n",
      "Score with test data 0.7593028691869904\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in y_train.T:\n",
    "    param = Rf(x_train, i)\n",
    "    reg_rf = RandomForestRegressor().set_params(**param)\n",
    "    reg_rf.fit(x_train, i)\n",
    "    prediction = reg_rf.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "\n",
    "    print(\"Score with test data\",reg_rf.score(x_test, y_test[:,j]))\n",
    "    print('new data\\n\\n\\n\\n\\n\\n')\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.235 (std: 0.011)\n",
      "Parameters: {'shrinking': True, 'kernel': 'linear', 'gamma': 'scale'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.209 (std: 0.012)\n",
      "Parameters: {'shrinking': True, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.166 (std: 0.009)\n",
      "Parameters: {'shrinking': True, 'kernel': 'sigmoid', 'gamma': 'auto'}\n",
      "\n",
      "RMSE on test data :  96323.17390262117\n",
      "Score with test data 0.24382337722455238\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.234 (std: 0.011)\n",
      "Parameters: {'shrinking': True, 'kernel': 'linear', 'gamma': 'scale'}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.234 (std: 0.011)\n",
      "Parameters: {'shrinking': True, 'kernel': 'linear', 'gamma': 'auto'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.166 (std: 0.009)\n",
      "Parameters: {'shrinking': True, 'kernel': 'sigmoid', 'gamma': 'auto'}\n",
      "\n",
      "RMSE on test data :  96068.89338832871\n",
      "Score with test data 0.24328107562813428\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.209 (std: 0.012)\n",
      "Parameters: {'shrinking': True, 'kernel': 'rbf', 'gamma': 'auto'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.166 (std: 0.009)\n",
      "Parameters: {'shrinking': False, 'kernel': 'sigmoid', 'gamma': 'scale'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.123 (std: 0.008)\n",
      "Parameters: {'shrinking': False, 'kernel': 'poly', 'gamma': 'auto'}\n",
      "\n",
      "RMSE on test data :  95662.5477884012\n",
      "Score with test data 0.24682390274114285\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.209 (std: 0.012)\n",
      "Parameters: {'shrinking': False, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.209 (std: 0.012)\n",
      "Parameters: {'shrinking': True, 'kernel': 'rbf', 'gamma': 'auto'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.166 (std: 0.009)\n",
      "Parameters: {'shrinking': True, 'kernel': 'sigmoid', 'gamma': 'scale'}\n",
      "\n",
      "RMSE on test data :  95550.49468825829\n",
      "Score with test data 0.24691885250268708\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in y_train.T:\n",
    "    param = Svr(x_train, i)\n",
    "    reg_svr = svm.SVR().set_params(**param)\n",
    "    reg_svr.fit(x_train, i)\n",
    "    prediction = reg_svr.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "\n",
    "    print(\"Score with test data\",reg_svr.score(x_test, y_test[:,j]))\n",
    "    print('new data\\n\\n\\n\\n\\n\\n')\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.650 (std: 0.015)\n",
      "Parameters: {'n_estimators': 11, 'loss': 'exponential'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.635 (std: 0.060)\n",
      "Parameters: {'n_estimators': 10, 'loss': 'square'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.629 (std: 0.021)\n",
      "Parameters: {'n_estimators': 7, 'loss': 'linear'}\n",
      "\n",
      "RMSE on test data :  50474.88083966188\n",
      "Score with test data 0.6037513779714642\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.664 (std: 0.027)\n",
      "Parameters: {'n_estimators': 15, 'loss': 'linear'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.652 (std: 0.027)\n",
      "Parameters: {'n_estimators': 18, 'loss': 'linear'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.610 (std: 0.027)\n",
      "Parameters: {'n_estimators': 7, 'loss': 'exponential'}\n",
      "\n",
      "RMSE on test data :  50272.186758007476\n",
      "Score with test data 0.604014226170293\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.639 (std: 0.029)\n",
      "Parameters: {'n_estimators': 16, 'loss': 'exponential'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.634 (std: 0.046)\n",
      "Parameters: {'n_estimators': 10, 'loss': 'square'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.565 (std: 0.045)\n",
      "Parameters: {'n_estimators': 28, 'loss': 'linear'}\n",
      "\n",
      "RMSE on test data :  49249.03482168167\n",
      "Score with test data 0.6122495511743291\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.664 (std: 0.040)\n",
      "Parameters: {'n_estimators': 13, 'loss': 'linear'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.644 (std: 0.019)\n",
      "Parameters: {'n_estimators': 13, 'loss': 'exponential'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.633 (std: 0.051)\n",
      "Parameters: {'n_estimators': 15, 'loss': 'square'}\n",
      "\n",
      "RMSE on test data :  41999.80738809178\n",
      "Score with test data 0.6689785516476553\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in y_train.T:\n",
    "    param = Ada(x_train, i)\n",
    "    reg_ada = AdaBoostRegressor().set_params(**param)\n",
    "    reg_ada.fit(x_train, i)\n",
    "    prediction = reg_ada.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "\n",
    "    print(\"Score with test data\",reg_ada.score(x_test, y_test[:,j]))\n",
    "    print('new data\\n\\n\\n\\n\\n\\n')\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=25. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.405 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.405 (std: 0.013)\n",
      "Parameters: {'normalize': False, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.405 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': False}\n",
      "\n",
      "RMSE on test data :  75006.6588197098\n",
      "Score with test data 0.41116680800719585\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=25. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': False}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': False, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': False, 'fit_intercept': True, 'copy_X': False}\n",
      "\n",
      "RMSE on test data :  74757.12077488816\n",
      "Score with test data 0.4111504148044693\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=25. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': False, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': False}\n",
      "\n",
      "RMSE on test data :  74776.27710591424\n",
      "Score with test data 0.4112669392544873\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=25. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': False, 'fit_intercept': True, 'copy_X': True}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.404 (std: 0.013)\n",
      "Parameters: {'normalize': True, 'fit_intercept': True, 'copy_X': False}\n",
      "\n",
      "RMSE on test data :  74668.02655348669\n",
      "Score with test data 0.4115040084123234\n",
      "new data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in y_train.T:\n",
    "    param = LR(x_train, i)\n",
    "    reg_lr = LinearRegression().set_params(**param)\n",
    "    reg_lr.fit(x_train, i)\n",
    "    prediction = reg_lr.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "\n",
    "    print(\"Score with test data\",reg_lr.score(x_test, y_test[:,j]))\n",
    "    print('new data\\n\\n\\n\\n\\n\\n')\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4610fdd51d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mreg_gp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreg_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2701a16c157d>\u001b[0m in \u001b[0;36mGP\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   }\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mrandomCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2701a16c157d>\u001b[0m in \u001b[0;36mrandomCV\u001b[0;34m(clf, X, y, param_grid, n_iter, cv)\u001b[0m\n\u001b[1;32m     19\u001b[0m     random_search = RandomizedSearchCV(clf, param_distributions = param_grid,\n\u001b[1;32m     20\u001b[0m           n_iter = n_iter, cv = cv, iid = False)\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_marginal_likelihood_value_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_marginal_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Precompute quantities required for predictions which are independent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_indices_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    762\u001b[0m                                        K2_gradient * K1[:, :, np.newaxis]))\n\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0mlength_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_length_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m             \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlength_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqeuclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;31m# convert from upper-triangular matrix to square matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mpdist\u001b[0;34m(X, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2002\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m         \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in y_train.T:\n",
    "    param = GP(x_train, i)\n",
    "    reg_gp = GaussianProcessRegressor().set_params(**param)\n",
    "    reg_gp.fit(x_train, i)\n",
    "    prediction = reg_gp.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "\n",
    "    print(\"Score with test data\",reg_gp.score(x_test, y_test[:,j]))\n",
    "    print('new data\\n\\n\\n\\n\\n\\n')\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 13) (20000,)\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.888 (std: 0.006)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 9, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.887 (std: 0.005)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 12, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.886 (std: 0.005)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'constant', 'hidden_layer_sizes': 16, 'activation': 'tanh'}\n",
      "\n",
      "RMSE on test data :  195772.58127573403\n",
      "Score with test data -0.30667781955403384\n",
      "(20000, 13) (20000,)\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.887 (std: 0.004)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': True, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 14, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.887 (std: 0.006)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'constant', 'hidden_layer_sizes': 13, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.885 (std: 0.007)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 9, 'activation': 'logistic'}\n",
      "\n",
      "RMSE on test data :  195685.3623583556\n",
      "Score with test data -0.30713962162840286\n",
      "(20000, 13) (20000,)\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.887 (std: 0.006)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 18, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.883 (std: 0.006)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'constant', 'hidden_layer_sizes': 13, 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.882 (std: 0.006)\n",
      "Parameters: {'solver': 'adam', 'shuffle': True, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 15, 'activation': 'relu'}\n",
      "\n",
      "RMSE on test data :  195555.9124166003\n",
      "Score with test data -0.3071769256756043\n",
      "(20000, 13) (20000,)\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.887 (std: 0.005)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': False, 'learning_rate': 'invscaling', 'hidden_layer_sizes': 19, 'activation': 'tanh'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.885 (std: 0.006)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': True, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 13, 'activation': 'logistic'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.884 (std: 0.005)\n",
      "Parameters: {'solver': 'lbfgs', 'shuffle': True, 'learning_rate': 'adaptive', 'hidden_layer_sizes': 11, 'activation': 'tanh'}\n",
      "\n",
      "RMSE on test data :  195762.21882709654\n",
      "Score with test data -0.3068704687022066\n"
     ]
    }
   ],
   "source": [
    "# # --------------->\n",
    "for i in y_train_nn.T:\n",
    "    print(x_train.shape, i.shape)\n",
    "    param = NN(x_train, i)\n",
    "    reg_nn = MLPRegressor().set_params(**param)\n",
    "    reg_nn.fit(x_train, i)\n",
    "\n",
    "    prediction = reg_nn.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test[:,j], prediction)\n",
    "\n",
    "    print(\"RMSE on test data : \", rmse)\n",
    "    print(\"Score with test data\",reg_nn.score(x_test, y_test[:,j]))\n",
    "    j+=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "9r.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
