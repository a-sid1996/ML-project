{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "from io import StringIO\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "np.set_printoptions(precision=3, suppress=True) \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[540.  ,   0.  ,   0.  , ..., 676.  ,  28.  ,  79.99],\n",
       "       [540.  ,   0.  ,   0.  , ..., 676.  ,  28.  ,  61.89],\n",
       "       [332.5 , 142.5 ,   0.  , ..., 594.  , 270.  ,  40.27],\n",
       "       ...,\n",
       "       [148.5 , 139.4 , 108.6 , ..., 780.  ,  28.  ,  23.7 ],\n",
       "       [159.1 , 186.7 ,   0.  , ..., 788.9 ,  28.  ,  32.77],\n",
       "       [260.9 , 100.5 ,  78.3 , ..., 761.5 ,  28.  ,  32.4 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('compresive_strength_concrete.csv',  skiprows=1, delimiter=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concrete:\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    # reading data \n",
    "    def read_data(self):        \n",
    "        #Dropping not predictive attributes : instant\n",
    "        data = np.loadtxt('compresive_strength_concrete.csv',  skiprows=1, delimiter=',')\n",
    "        return data\n",
    "    \n",
    "    def preprocessing(self, data):               \n",
    "        # splitting data\n",
    "        X = data[:,:-1]\n",
    "        y = data[:,-1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)        \n",
    "        #preprocessing using standard scaler\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        return X_train, y_train, X_test, y_test\n",
    "        \n",
    "    def cv_SVR(self, X, y):\n",
    "        #scorer = make_scorer(neg_mean_squared_error)\n",
    "        C_grid = [0.1, 1, 10]\n",
    "        gamma_grid = np.logspace(-2, 1, 4)[0:3]\n",
    "        svm = sklearn.svm.SVR(kernel='rbf')\n",
    "        param_grid = { 'C' : C_grid, 'gamma' : gamma_grid, 'kernel' : ['rbf', 'sigmoid',  'linear']}\n",
    "        gridcv = sklearn.model_selection.GridSearchCV(svm, param_grid, n_jobs=-1, verbose=1, cv=3)\n",
    "        #, scoring = 'neg_mean_squared_error'\n",
    "        gridcv.fit(X_train, y_train)\n",
    "        print(\"best parameters:\", gridcv.best_params_)\n",
    "        print(\"%.1f%%  on validation sets (average)\" % (gridcv.best_score_*100))\n",
    "        return gridcv.best_params_\n",
    "    \n",
    "    def cv_DTR(self, X, y):\n",
    "        dt = DecisionTreeRegressor()\n",
    "        param_grid = {\n",
    "            \"min_samples_split\" : np.random.random_sample((100,)),\n",
    "            \"min_samples_leaf\" : np.arange(1,6),\n",
    "            'max_depth': range(1, 20),\n",
    "            'criterion' : ['mse', 'mae', 'friedman_mse'],\n",
    "            'splitter' : ['best', 'random'],\n",
    "        }\n",
    "        return Concrete.randomCV(dt, X, y, param_grid, 50, 6)\n",
    "        \n",
    "    def cv_RandomForest(self, X, y):\n",
    "        rf = RandomForestRegressor()\n",
    "        param_grid = {\n",
    "            #\"n_estimators\" : [10*x for x in np.arange(1,25)],\n",
    "            \"min_samples_split\" : np.random.random_sample((100,)),\n",
    "            \"min_samples_leaf\" : np.arange(1,6),\n",
    "            'max_depth': range(1, 20),\n",
    "        }\n",
    "        return Concrete.randomCV(rf, X, y, param_grid, 40, 6)\n",
    "    \n",
    "    def cv_GP(self, X, y):\n",
    "        clf = GaussianProcessRegressor()\n",
    "        param_grid = {\n",
    "            \n",
    "        \"normalize_y\" : [True, False],\n",
    "        \"copy_X_train\" : [True, False],\n",
    "        \"alpha\" : np.linspace(0, 5, 100),\n",
    "        }\n",
    "        return Concrete.randomCV(clf, X, y, param_grid, 25, 6)\n",
    "        \n",
    "    def cv_adaBoost(self, X, y):\n",
    "        #scorer = make_scorer(precision_score)\n",
    "        ada_boost = AdaBoostRegressor(n_estimators=50, learning_rate=1)\n",
    "        param_grid = {'n_estimators': range(1, 50), 'learning_rate': [0.1, 0.5, 1]}\n",
    "        gridcv = sklearn.model_selection.GridSearchCV(ada_boost, param_grid, verbose=1, cv=3, n_jobs=-1)\n",
    "                                                      #, scoring='explained_variance')\n",
    "        gridcv.fit(X, y)\n",
    "        print(\"best parameters:\", gridcv.best_params_)\n",
    "        print(\"%.1f%% validation on validation sets (average)\" % (gridcv.best_score_))\n",
    "        return gridcv.best_params_\n",
    "    \n",
    "    def cv_linReg(self, X, y):\n",
    "        lr = LinearRegression()\n",
    "        param_grid = {\n",
    "            \"fit_intercept\" : [True, False],\n",
    "        }\n",
    "        return Concrete.randomCV(lr, X, y, param_grid, 40, 6)\n",
    "        \n",
    "   \n",
    "    \n",
    "    def cv_NNRegressor(self, X, y):\n",
    "        nn = sklearn.neural_network.MLPRegressor()\n",
    "\n",
    "        param_grid ={\n",
    "                    'hidden_layer_sizes' : range(2,100),\n",
    "                    \"activation\" : ['identity', 'logistic', 'tanh', 'relu']\n",
    "                    }\n",
    "        return Concrete.randomCV(nn, X, y, param_grid, 100, 6)\n",
    "        \n",
    "    def randomCV(clf, X, y, param_grid, n_iter, cv):\n",
    "        #scorer = make_scorer(precision_score)\n",
    "        random_search = RandomizedSearchCV(clf, param_distributions = param_grid, n_iter = n_iter, cv = cv, iid = False, \n",
    "                                           verbose=1, n_jobs=-1)\n",
    "        #scoring = \"explained_variance\"\n",
    "        random_search.fit(X, y)\n",
    "        #print(random_search.cv_results_)\n",
    "        Concrete.report(random_search.cv_results_)\n",
    "        return random_search.best_params_\n",
    "    \n",
    "    def report(results, n_top=1):\n",
    "        for i in range(1, n_top + 1):\n",
    "            candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "            k = 0\n",
    "            for candidate in candidates:                \n",
    "                print(\"Model with rank: {0}\".format(i))\n",
    "                print(\"Variance on validation data: {0:.3f} (std: {1:.3f})\".format(\n",
    "                      results['mean_test_score'][candidate],\n",
    "                      results['std_test_score'][candidate]))\n",
    "                print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "                print(\"\")\n",
    "                k += 1\n",
    "                if k == 3:\n",
    "                    break\n",
    "                \n",
    "    def predict(self, model, X_test, y_test):\n",
    "        predict = model.predict(X_test)\n",
    "        predict[predict<0] =0\n",
    "        rmse = mean_squared_error(y_test, predict)\n",
    "        print(\"MSE on test data : \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.919, -0.881, -0.846, ..., -0.46 , -0.644, -0.288],\n",
       "       [ 0.915, -0.881, -0.846, ...,  0.852, -0.187, -0.288],\n",
       "       [ 0.232,  0.704, -0.846, ..., -0.981, -0.625, -0.288],\n",
       "       ...,\n",
       "       [-1.294, -0.881,  1.868, ..., -0.37 ,  0.874, -0.288],\n",
       "       [-0.38 ,  3.192, -0.846, ..., -0.388, -1.343, -0.288],\n",
       "       [-0.835,  2.383, -0.846, ..., -0.54 , -0.704,  0.716]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------SVR--------\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "78.5%  on validation sets (average)\n",
      "MSE on test data :  46.61412620783457\n",
      "---------DTR--------\n",
      "Fitting 6 folds for each of 50 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Variance on validation data: 0.770 (std: 0.028)\n",
      "Parameters: {'splitter': 'best', 'min_samples_split': 0.029864188153626903, 'min_samples_leaf': 3, 'max_depth': 19, 'criterion': 'mae'}\n",
      "\n",
      "MSE on test data :  63.28207220873787\n",
      "---------Random Forrest Regressor--------\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Variance on validation data: 0.821 (std: 0.015)\n",
      "Parameters: {'min_samples_split': 0.04158547816075708, 'min_samples_leaf': 2, 'max_depth': 17}\n",
      "\n",
      "MSE on test data :  43.18212179887168\n",
      "---------Adaboost Regressor--------\n",
      "Fitting 3 folds for each of 147 candidates, totalling 441 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 out of 441 | elapsed:    8.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 441 out of 441 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 1, 'n_estimators': 48}\n",
      "0.8% validation on validation sets (average)\n",
      "MSE on test data :  54.250622587752765\n",
      "---------Gaussian Process Regressor--------\n",
      "Fitting 6 folds for each of 25 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Variance on validation data: 0.829 (std: 0.022)\n",
      "Parameters: {'normalize_y': True, 'copy_X_train': False, 'alpha': 0.35353535353535354}\n",
      "\n",
      "MSE on test data :  37.86086474231978\n",
      "---------Linear Regressor--------\n",
      "Fitting 6 folds for each of 2 candidates, totalling 12 fits\n",
      "Model with rank: 1\n",
      "Variance on validation data: 0.599 (std: 0.030)\n",
      "Parameters: {'fit_intercept': True}\n",
      "\n",
      "MSE on test data :  95.61717380589968\n",
      "---------NN Regressor--------\n",
      "Fitting 6 folds for each of 100 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsal\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 2 is smaller than n_iter=40. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Variance on validation data: 0.688 (std: 0.022)\n",
      "Parameters: {'hidden_layer_sizes': 97, 'activation': 'tanh'}\n",
      "\n",
      "MSE on test data :  63.869742902766546\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    obj = Concrete()\n",
    "    data = obj.read_data()\n",
    "    X_train, y_train, X_test, y_test = obj.preprocessing(data)\n",
    "    #print(X_train)\n",
    "    #print(y_train)\n",
    "    print('---------SVR--------')\n",
    "    model = obj.cv_SVR(X_train, y_train)\n",
    "    reg = sklearn.svm.SVR().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)\n",
    "    print('---------DTR--------')\n",
    "    model = obj.cv_DTR(X_train, y_train)\n",
    "    reg = sklearn.tree.DecisionTreeRegressor().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)\n",
    "    print('---------Random Forrest Regressor--------') \n",
    "    model = obj.cv_RandomForest(X_train, y_train)\n",
    "    reg = sklearn.ensemble.RandomForestRegressor().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)\n",
    "    print('---------Adaboost Regressor--------')\n",
    "    model = obj.cv_adaBoost(X_train, y_train)\n",
    "    reg = sklearn.ensemble.AdaBoostRegressor().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)\n",
    "    print('---------Gaussian Process Regressor--------')\n",
    "    model = obj.cv_GP(X_train, y_train)\n",
    "    reg = sklearn.gaussian_process.GaussianProcessRegressor().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)\n",
    "    print('---------Linear Regressor--------')\n",
    "    model = obj.cv_linReg(X_train, y_train)\n",
    "    reg = LinearRegression().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)\n",
    "    print('---------NN Regressor--------')\n",
    "    model = obj.cv_NNRegressor(X_train, y_train)\n",
    "    reg = MLPRegressor().set_params(**model).fit(X_train, y_train)\n",
    "    obj.predict(reg, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
