{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6788\n",
      "[3. 8. 0. ... 5. 0. 7.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(precision=3, suppress=True)  # Print array values as 0.0023 instead of 2.352e-3\n",
    "torch.set_printoptions(precision=3, sci_mode=False)\n",
    "\n",
    "\n",
    "class CNN_CIFAR:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def unpickle(self,file):\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "    def scale_data(self,data):\n",
    "        data = data/255\n",
    "        data = (2*data)-1\n",
    "        return data\n",
    "    \n",
    "    def build_model(self):\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        filter_size = 5\n",
    "        num_filters = 10\n",
    "        pool_size = 2\n",
    "        \n",
    "        model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3,\n",
    "                    out_channels=num_filters,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride = 1,\n",
    "                    padding=2\n",
    "                           ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=pool_size),\n",
    "            torch.nn.Conv2d(in_channels=num_filters,\n",
    "                    out_channels=2*num_filters,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride = 1,\n",
    "                    padding=2\n",
    "                           ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=pool_size, stride=pool_size),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear((2*num_filters * 16**2)//pool_size**2, 10),           \n",
    "        )\n",
    "        model = model.float()\n",
    "        return model\n",
    "    \n",
    "    def train_model(self,model,X_train,y_train,batch_size,epoch_num):\n",
    "        #define loss function as entropy loss funcion\n",
    "        model.float()\n",
    "        loss = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss.float()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-3)\n",
    "        for epoch in range(1, epoch_num+1):\n",
    "            for i in range(0, len(X_train), batch_size):        \n",
    "                X = X_train[i:i+batch_size]\n",
    "                y = y_train[i:i+batch_size]\n",
    "\n",
    "                y_pred = model(X)\n",
    "                #print(y_pred.shape)\n",
    "                #print(y.shape)\n",
    "                l = loss(y_pred, torch.max(y, 1)[1])\n",
    "        \n",
    "                model.zero_grad()\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            print(\"Epoch %d final minibatch had loss %.4f\" % (epoch, l.item()))\n",
    "        return model\n",
    "    \n",
    "    def testing(self):      \n",
    "        X_dtest = self.unpickle('test_batch')\n",
    "        X_test,y_test = X_dtest[b'data'],(X_dtest[b'labels'])\n",
    "        X_test = self.scale_data(X_test)\n",
    "        X_test = X_test.reshape(-1,3,32,32)\n",
    "        y_test =  np.asarray(y_test) \n",
    "        X_test = torch.tensor(X_test)\n",
    "        X_test = X_test.float()\n",
    "        model = pickle.load(open('finalized_model2.sav', 'rb'))\n",
    "        \n",
    "        y_pred = model(X_test.float())\n",
    "        \n",
    "        y_predicted = np.zeros((y_pred.shape[0]))\n",
    "        for i in range(y_pred.shape[0]):\n",
    "             y_predicted[i] = np.where(y_pred[i] == max(y_pred[i]))[0][0]\n",
    "        \n",
    "        print(accuracy_score(y_test, y_predicted))\n",
    "        print(y_predicted)\n",
    "       \n",
    "        \n",
    "    \n",
    "    def start(self):\n",
    "        print(\"Unpickling Data files begin\")\n",
    "        #unpickling the data set\n",
    "        file1 = 'data_batch_1'\n",
    "        file2 = 'data_batch_2'\n",
    "        file3 = 'data_batch_3'\n",
    "        file4 = 'data_batch_4'\n",
    "        file5 = 'data_batch_5'\n",
    "        test_file = 'test_batch'\n",
    "        \n",
    "        X_d1 = self.unpickle(file1)\n",
    "        X_d2 = self.unpickle(file2)\n",
    "        X_d3 = self.unpickle(file3)\n",
    "        X_d4 = self.unpickle(file4)\n",
    "        X_d5 = self.unpickle(file5)\n",
    "        \n",
    "        X_dtest = self.unpickle(test_file)\n",
    "        \n",
    "        print(list(X_d1.keys()))        \n",
    "        \n",
    "        X1,y1 = X_d1[b'data'],(X_d1[b'labels'])\n",
    "        X2,y2 = X_d2[b'data'],(X_d2[b'labels'])\n",
    "        X3,y3 = X_d3[b'data'],(X_d3[b'labels'])\n",
    "        X4,y4 = X_d4[b'data'],(X_d4[b'labels'])\n",
    "        X5,y5 = X_d5[b'data'],(X_d5[b'labels'])\n",
    "        \n",
    "        X_test,y_test = X_dtest[b'data'],(X_dtest[b'labels'])\n",
    "        \n",
    "        \n",
    "        #print(X1[0].reshape(3,32,32).transpose(1,2,0).shape)\n",
    "        #plt.imshow(X1[0].reshape(3,32,32).transpose(1,2,0))\n",
    "\n",
    "        \n",
    "        X = np.vstack((X1,X2,X3,X4,X5))\n",
    "        #X = X1\n",
    "        y = y1+y2+y3+y4+y5\n",
    "        #y = y1\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        model = self.build_model()\n",
    "\n",
    "        \n",
    "        #Rescaling pixel data to fit between -1 and 1\n",
    "        X = self.scale_data(X)\n",
    "       \n",
    "        \n",
    "        X = X.reshape(-1,3,32,32)\n",
    "        print(X.dtype)\n",
    "        \n",
    "        y = label_binarize(y,classes = np.arange(0,10,1))\n",
    "        X,y = torch.tensor(X), torch.tensor(y)\n",
    "        \n",
    "        X = X.float()\n",
    "        y = y.float()\n",
    "        #predictions before training\n",
    "        y_pred = model(X[:5].float())\n",
    "        print(y_pred)\n",
    "        print(torch.softmax(model(X[:5].float()), dim=1))\n",
    "            \n",
    "        model = self.train_model(model,X,y,500,20)\n",
    "                \n",
    "        filename = 'finalized_model2.sav'\n",
    "        pickle.dump(model, open(filename, 'wb'))\n",
    "        \n",
    "        #predictions after training\n",
    "        y_pred = model(X[:5].float())\n",
    "        print(y_pred)\n",
    "        print(torch.softmax(model(X[:5].float()), dim=1))\n",
    "        y_pred = torch.softmax(model(X[:5].float()), dim=1)\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "obj = CNN_CIFAR()\n",
    "#obj.start()\n",
    "obj.testing()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = CNN_CIFAR()\n",
    "obj.testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('finalized_model.sav', 'rb'))\n",
    "\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
